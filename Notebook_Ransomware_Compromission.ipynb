{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98bc697d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "from googlesearch import search\n",
    "import re\n",
    "import os\n",
    "import zipfile\n",
    "from tld import get_tld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77d916ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def creation_Dataframe_Ransom(url,delta_Days):\n",
    "    df = pd.read_json(url)\n",
    "    now = datetime.datetime.now()\n",
    "    yesterday_date= datetime.datetime.now() - datetime.timedelta(days=int(delta_Days))\n",
    "    df = df.loc[df[\"discovered\"].between(str(yesterday_date), str(now))]\n",
    "    df = df.reset_index(drop=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a44011f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def url_Creation(dataframe_Ransom,list_Url):\n",
    "    url_Pattern_No_HTTP = re.compile('^[-a-zA-Z0-9@:%._\\\\+~#=]{1,256}\\\\.[a-zA-Z0-9()]{1,6}\\\\b(?:[-a-zA-Z0-9()@:%_\\\\+.~#?&\\\\/=]*)$')\n",
    "    url_Pattern_With_HTTP = re.compile('^https?:\\\\/\\\\/(?:www\\\\.)?[-a-zA-Z0-9@:%._\\\\+~#=]{1,256}\\\\.[a-zA-Z0-9()]{1,6}\\\\b(?:[-a-zA-Z0-9()@:%_\\\\+.~#?&\\\\/=]*)$')\n",
    "    for Victim in dataframe_Ransom['post_title']:\n",
    "        if url_Pattern_No_HTTP.match(str(Victim)):\n",
    "            list_Url.append(Victim)\n",
    "        elif url_Pattern_With_HTTP.match(str(Victim)):\n",
    "            list_Url.append(Victim)        \n",
    "        else:\n",
    "            for created_Url in search(Victim, tld=\"com\", num=1, stop=1, pause=2):\n",
    "                list_Url.append(created_Url)   \n",
    "    dataframe_Ransom[\"url_of_website\"] = pd.Series(list_Url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09df8b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def country_Creation(dataframe_Ransom, list_Country):\n",
    "    tld_df = pd.read_json(\"tld.json\")\n",
    "    list_tld=[]\n",
    "    list_Country=[]\n",
    "    list_sld=['gov.',\"edu.\",\"ac.\",\"in.\",\"co.\",\"com.\",\"im.\"]\n",
    "    url_Pattern_No_HTTP = re.compile('^[-a-zA-Z0-9@:%._\\\\+~#=]{1,256}\\\\.[a-zA-Z0-9()]{1,6}\\\\b(?:[-a-zA-Z0-9()@:%_\\\\+.~#?&\\\\/=]*)$')\n",
    "    url_Pattern_With_HTTP = re.compile('^https?:\\\\/\\\\/(?:www\\\\.)?[-a-zA-Z0-9@:%._\\\\+~#=]{1,256}\\\\.[a-zA-Z0-9()]{1,6}\\\\b(?:[-a-zA-Z0-9()@:%_\\\\+.~#?&\\\\/=]*)$')\n",
    "    for url_Victim in dataframe_Ransom['url_of_website']:\n",
    "        if url_Pattern_No_HTTP.match(str(url_Victim)):\n",
    "            list_tld.append(get_tld(url_Victim, fix_protocol=True))\n",
    "        elif url_Pattern_With_HTTP.match(str(url_Victim)):\n",
    "            list_tld.append(get_tld(url_Victim))\n",
    "\n",
    "    dataframe_Ransom[\"TLD\"] = pd.Series(list_tld)\n",
    "    for tld in dataframe_Ransom['TLD']:\n",
    "        for i in list_sld:\n",
    "            if i in tld:\n",
    "                tld=tld.replace(i,\"\")\n",
    "        for i in range(len(tld_df)):\n",
    "            if tld == tld_df['tlds'][i]:\n",
    "                list_Country.append(tld_df['country'][i])\n",
    "    dataframe_Ransom[\"Country\"] = pd.Series(list_Country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6a5e26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_Creation(dataframe_Ransom):\n",
    "    var1=\"Ransomware_\"\n",
    "    date= datetime.datetime.now()\n",
    "    date_formatted=date.strftime(\"%d_%m_%Y\")\n",
    "    dataframe_Ransom.to_csv(f'{var1}{date_formatted}.csv')\n",
    "    dataframe_Ransom.to_excel(f'{var1}{date_formatted}.xlsx')\n",
    "    Output_Zip = zipfile.ZipFile(f'{var1}{date_formatted}.zip', 'w')\n",
    "    Output_Zip.write(f'{var1}{date_formatted}.csv')\n",
    "    Output_Zip.write(f'{var1}{date_formatted}.xlsx')\n",
    "    Output_Zip.close()\n",
    "    os.remove(f'{var1}{date_formatted}.xlsx')\n",
    "    os.remove(f'{var1}{date_formatted}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f92545a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def misc():\n",
    "    if os.path.isfile(\".google-cookie\"):\n",
    "        os.remove(\".google-cookie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e0044ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    url = \"https://raw.githubusercontent.com/joshhighet/ransomwatch/main/posts.json\"\n",
    "    url_List = []\n",
    "    country_list=[]\n",
    "    Dataframe_Ransom=creation_Dataframe_Ransom(url,2)\n",
    "    url_Creation(Dataframe_Ransom,url_List)\n",
    "    country_Creation(Dataframe_Ransom, country_list)\n",
    "    output_Creation(Dataframe_Ransom)\n",
    "    misc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8b58335",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
